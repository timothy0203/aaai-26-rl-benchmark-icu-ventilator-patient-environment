{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data\n",
    "## Target\n",
    "- input: mimic_iv csv files\n",
    "    - cohort.csv\n",
    "    - ground_truth.csv\n",
    "    - baseline.csv\n",
    "    - vitalsign_gcs.csv\n",
    "    - vitalsign.csv\n",
    "    - ventilator_settings.csv\n",
    "- output: three csv files\n",
    "    - baseline_charttime_ground_truth.csv: variable length for each patients trajectory\n",
    "    - baseline_charttime_ground_truth_n_hr.csv: fixed length (e.g., 1hr(last), 24hr, or 48hr) for each patients trajectory\n",
    "    - baseline_charttime_ground_truth_mode_change.csv:\n",
    "        - ventilator_mode_group_change: change from Minimal Support to Complete Support set as -1, Complete Support to Minimal Support set as 1\n",
    "    - columns\n",
    "        - id_col: ['stay_id', 'before_weaning_hr']\n",
    "        - state_variables_col = ['age', 'gender', 'race', 'weight_kg', 'height_cm', 'tobacco', 'tidal_volume_observed', 'RSBI', 'minute_ventilation', 'heart_rate', 'sbp', 'dbp', 'mbp', 'resp_rate', 'spo2', 'gcs']\n",
    "        - action_variables_col = ['peep', 'fio2', 'respiratory_rate_set', 'tidal_volume_set', 'plateau_pressure', 'ventilator_mode_group']\n",
    "        - outcome_col = ['weaning_till_reintubation_hr', 'weaning_till_dod_hr']\n",
    "    - rows\n",
    "        - fixed rows: 7093 * 24 --> 6798 * 24 (after drop having whole miss features)\n",
    "        - variable rows: 7093 * each trajectroy length --> 6798 * each trajectroy length\n",
    "## Baseline Steps\n",
    "- category to onehot: gender and race\n",
    "## Charttime Steps\n",
    "### Generate template of each trajectory\n",
    "- category to numerical: ventilator_mode_group 0 minimal, 1 partial, 2 complete\n",
    "- stay_id and before_weaning_hr, can get extra 4 hr for fill missing value before ventilation starttime\n",
    "- fixed length: 4 + 24 = 28 rows for each trajectroy\n",
    "- variable length: 4 + trajectory length rows\n",
    "    - based on cohort.csv, calculate the length of endtime and start time, then generate a dictionary: stay_id -> vent_hr\n",
    "- Do the second version, more general for two\n",
    "## Remove outliers\n",
    "- Based on Tukey's fences for outlier detection, which are defines 'non outlier' data as everything in the range ``[(first quartile - 1.5 IQR), (third quartile + 1.5 IQR)]\n",
    "- Based on textbook and paper, we get the reasonable range for each variables\n",
    "- we choose the looser one as bound to exclude the outliers \n",
    "## Fill missing value\n",
    "- KNN for baseline\n",
    "- ffill and bfill for charttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "- cohort.csv: subject_id, stay_id, starttime, endtime (start/end time of ventilation event)\n",
    "- ground_truth.csv: subject_id, stay_id, starttime, endtime, reintubation_time_gap_hr, dod\n",
    "- baseline.csv: gender, race, age, weight, height, tobacco\n",
    "- vitalsign_gcs.csv: subject_id, stay_id, charttime, gcs\n",
    "- vitalsign.csv: subject_id, stay_id, charttime, heart_rate, resp_rate, sbp, dbp, mbp, spo2\n",
    "- ventilator_settings.csv: subject_id, stay_id, charttime, peep, fio2, tidal_volume_observed, tidal_volume_set, respiratory_rate_set, plateau_pressure, ventilator_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_flag = True\n",
    "DATA_SOURCE = \"MIMIC-III\" # \"MIMIC-III\", \"eICU\", \"MIMIC-IV\"\n",
    "if DATA_SOURCE == \"eICU\":\n",
    "    selected_columns = ['peep', 'respiratory_rate_set', 'fio2', 'heart_rate', 'resp_rate', 'spo2', 'sbp', 'dbp', 'mbp'] # TODO\n",
    "else:\n",
    "    selected_columns = ['peep', 'respiratory_rate_set', 'fio2', 'tidal_volume_set', 'heart_rate', 'resp_rate', 'spo2', 'sbp', 'dbp', 'mbp', 'tidal_volume_observed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_path = \"../data/mimic_iii\"\n",
    "# prefix_path = \"../data/eICU\"\n",
    "# prefix_path = \"../data/mimic_iv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(prefix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(f'{prefix_path}/baseline.csv')\n",
    "cohort_df = pd.read_csv(f'{prefix_path}/cohort.csv')\n",
    "ground_truth_df = pd.read_csv(f'{prefix_path}/ground_truth.csv')\n",
    "ventilator_settings_df = pd.read_csv(f'{prefix_path}/ventilator_settings.csv')\n",
    "vitalsign_df = pd.read_csv(f'{prefix_path}/vitalsign.csv')\n",
    "vitalsign_gcs_df = pd.read_csv(f'{prefix_path}/vitalsign_gcs.csv')\n",
    "if DATA_SOURCE != \"eICU\":\n",
    "    ground_truth_deathtime_df = pd.read_csv(f'{prefix_path}/ground_truth_deathtime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert and format timestamps\n",
    "def convert_timestamps(df, columns):\n",
    "    for col in columns:\n",
    "        # Convert to datetime\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "        # Format datetime to the desired format\n",
    "        df[col] = df[col].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_minutes_to_datetime(df, column='charttime'):\n",
    "    # Make a copy of the dataframe to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert minutes to seconds (multiply by 60)\n",
    "    # Then convert seconds to datetime\n",
    "    df[column] = pd.to_datetime(df[column].astype(float) * 60, unit='s')\n",
    "    \n",
    "    return df\n",
    "\n",
    "if DATA_SOURCE == \"eICU\":\n",
    "    # Rename 'patientunitstayid' to 'stay_id' in each DataFrame\n",
    "    baseline_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "    cohort_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "    ground_truth_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "    ventilator_settings_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "    vitalsign_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "    vitalsign_gcs_df.rename(columns={'patientunitstayid': 'stay_id'}, inplace=True)\n",
    "\n",
    "    # Convert gender values from \"Female\"/\"Male\" to \"F\"/\"M\"\n",
    "    baseline_df['gender'] = baseline_df['gender'].replace({'Female': 'F', 'Male': 'M'})\n",
    "\n",
    "    # List of columns to convert\n",
    "    timestamp_columns = ['starttime', 'endtime']\n",
    "\n",
    "    # Convert timestamps in each DataFrame\n",
    "    baseline_df = convert_timestamps(baseline_df, timestamp_columns)\n",
    "    cohort_df = convert_timestamps(cohort_df, timestamp_columns)\n",
    "    ground_truth_df = convert_timestamps(ground_truth_df, timestamp_columns)\n",
    "    # Apply the conversion to each DataFrame\n",
    "    ventilator_settings_df = convert_minutes_to_datetime(ventilator_settings_df)\n",
    "    vitalsign_df = convert_minutes_to_datetime(vitalsign_df)\n",
    "    vitalsign_gcs_df = convert_minutes_to_datetime(vitalsign_gcs_df)\n",
    "\n",
    "    # Using the insert() method to add column at position 0 (first position)\n",
    "    baseline_df.insert(0, \"subject_id\", baseline_df[\"stay_id\"])\n",
    "    cohort_df.insert(0, \"subject_id\", cohort_df[\"stay_id\"])\n",
    "    ground_truth_df.insert(0, \"subject_id\", ground_truth_df[\"stay_id\"])\n",
    "    ventilator_settings_df.insert(0, \"subject_id\", ventilator_settings_df[\"stay_id\"])\n",
    "    vitalsign_df.insert(0, \"subject_id\", vitalsign_df[\"stay_id\"])\n",
    "    vitalsign_gcs_df.insert(0, \"subject_id\", vitalsign_gcs_df[\"stay_id\"])\n",
    "\n",
    "    # Calculate the difference in hours\n",
    "    baseline_df['time_diff'] = (pd.to_datetime(baseline_df['endtime']) - pd.to_datetime(baseline_df['starttime'])).dt.total_seconds() / 3600\n",
    "    cohort_df['time_diff'] = (pd.to_datetime(cohort_df['endtime']) - pd.to_datetime(cohort_df['starttime'])).dt.total_seconds() / 3600\n",
    "    ground_truth_df['time_diff'] = (pd.to_datetime(ground_truth_df['endtime']) - pd.to_datetime(ground_truth_df['starttime'])).dt.total_seconds() / 3600\n",
    "\n",
    "    # Drop rows where the difference is greater than 1500 hours\n",
    "    baseline_df = baseline_df[baseline_df['time_diff'] <= 1500]\n",
    "    cohort_df = cohort_df[cohort_df['time_diff'] <= 1500]\n",
    "    ground_truth_df = ground_truth_df[ground_truth_df['time_diff'] <= 1500]\n",
    "\n",
    "    # Drop the time_diff column as it's no longer needed\n",
    "    baseline_df = baseline_df.drop(columns=['time_diff'])\n",
    "    cohort_df = cohort_df.drop(columns=['time_diff'])\n",
    "    ground_truth_df = ground_truth_df.drop(columns=['time_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"MIMIC-III\":\n",
    "    # Rename 'icustay_id' to 'stay_id' in each DataFrame\n",
    "    baseline_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    cohort_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    ground_truth_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    ground_truth_deathtime_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    ventilator_settings_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    vitalsign_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)\n",
    "    vitalsign_gcs_df.rename(columns={'icustay_id': 'stay_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_df['height'].isna().sum()\n",
    "vitalsign_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_settings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"eICU\":\n",
    "    # there are 51 patients in eICU don't have any vital sign data\n",
    "    print(len(cohort_df.join(vitalsign_df.groupby(['stay_id', 'subject_id']).count(), how='left', on=['stay_id', 'subject_id'])[cohort_df.join(vitalsign_df.groupby(['stay_id', 'subject_id']).count(), how='left', on=['stay_id', 'subject_id'])[\"heart_rate\"].isna()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df.groupby(\"race\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category to one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Race mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ethnicity(ethnicity):\n",
    "    # Define the mappings\n",
    "    white_group = ['WHITE', 'WHITE - OTHER EUROPEAN', 'WHITE - RUSSIAN', 'WHITE - BRAZILIAN', 'WHITE - EASTERN EUROPEAN', 'Caucasian']\n",
    "    asian_group = ['ASIAN', 'ASIAN - CHINESE', 'ASIAN - SOUTH EAST ASIAN', 'ASIAN - ASIAN INDIAN', 'ASIAN - KOREAN', 'Asian']\n",
    "    black_group = ['BLACK/AFRICAN AMERICAN', 'BLACK/CAPE VERDEAN', 'BLACK/CARIBBEAN ISLAND', 'BLACK/AFRICAN', 'African American']\n",
    "    hispanic_group = ['HISPANIC/LATINO - PUERTO RICAN', 'HISPANIC OR LATINO', 'HISPANIC/LATINO - COLUMBIAN', \n",
    "                      'HISPANIC/LATINO - DOMINICAN', 'HISPANIC/LATINO - HONDURAN', 'HISPANIC/LATINO - CENTRAL AMERICAN', \n",
    "                      'HISPANIC/LATINO - GUATEMALAN', 'HISPANIC/LATINO - MEXICAN', 'HISPANIC/LATINO - SALVADORAN', 'Hispanic']\n",
    "    others_group = ['UNKNOWN', 'PATIENT DECLINED TO ANSWER', 'OTHER', 'UNABLE TO OBTAIN', 'PORTUGUESE', \n",
    "                    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER', 'AMERICAN INDIAN/ALASKA NATIVE', \n",
    "                    'MULTIPLE RACE/ETHNICITY', 'Native American', 'Other/Unknown']\n",
    "\n",
    "    # Categorize based on the mappings\n",
    "    if ethnicity in white_group:\n",
    "        return 'WHITE'\n",
    "    elif ethnicity in asian_group:\n",
    "        return 'ASIAN'\n",
    "    elif ethnicity in black_group:\n",
    "        return 'BLACK'\n",
    "    elif ethnicity in hispanic_group:\n",
    "        return 'HISPANIC'\n",
    "    else:\n",
    "        return 'OTHERS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocess_df = baseline_df\n",
    "baseline_preprocess_df['race_grouped'] = baseline_preprocess_df['race'].apply(group_ethnicity)\n",
    "# One-hot encode the race_grouped column\n",
    "baseline_preprocess_df = pd.get_dummies(baseline_preprocess_df, columns=['race_grouped'])\n",
    "baseline_preprocess_df = baseline_preprocess_df.drop(['race'], axis=1)\n",
    "baseline_preprocess_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: there are some stay_id have multiple race, choose one if not UNKNOWN or OTHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define priority order for race groups\n",
    "race_priority = ['race_grouped_ASIAN', 'race_grouped_BLACK', 'race_grouped_HISPANIC', 'race_grouped_WHITE', 'race_grouped_OTHERS']\n",
    "\n",
    "# Sort the DataFrame based on the priority order and `stay_id`\n",
    "baseline_preprocess_df['priority'] = baseline_preprocess_df[race_priority].idxmax(axis=1).apply(lambda x: race_priority.index(x))\n",
    "baseline_preprocess_df = baseline_preprocess_df.sort_values(by=['stay_id', 'priority']).drop(columns='priority')\n",
    "\n",
    "# Drop duplicate rows for each `stay_id`, keeping the first occurrence\n",
    "baseline_preprocess_df = baseline_preprocess_df.drop_duplicates(subset=['stay_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_preprocess_df['stay_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocess_df = pd.get_dummies(baseline_preprocess_df, columns=['gender'])\n",
    "baseline_preprocess_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    baseline_preprocess_df.to_csv(f\"{prefix_path}/baseline_preprocess.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charttime preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate template: stay_id and before_weaning_hr\n",
    "- add extra 4 hr for fill missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_4_HR_FLAG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_hr_df = cohort_df\n",
    "# Convert starttime and endtime to datetime\n",
    "cohort_hr_df['starttime'] = pd.to_datetime(cohort_hr_df['starttime'])\n",
    "cohort_hr_df['endtime'] = pd.to_datetime(cohort_hr_df['endtime'])\n",
    "\n",
    "# Calculate intubation_hr\n",
    "cohort_hr_df['intubation_hr'] = (cohort_hr_df['endtime'] - cohort_hr_df['starttime']).dt.total_seconds() / 3600\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    cohort_hr_df['intubation_hr_add_4hr'] = cohort_hr_df['intubation_hr'] + 4\n",
    "cohort_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_before_weaning_rows(stay_id, hours):\n",
    "    rows = []\n",
    "    for hr in range(int(hours), -1, -1):\n",
    "        rows.append({'stay_id': stay_id, 'before_weaning_hr': hr})\n",
    "    return rows\n",
    "\n",
    "# Create the charttime_template_df\n",
    "charttime_template_df = pd.DataFrame()\n",
    "\n",
    "for index, row in cohort_hr_df.iterrows():\n",
    "    stay_id = row['stay_id']\n",
    "    if EXTRA_4_HR_FLAG:\n",
    "        hours = row['intubation_hr_add_4hr']\n",
    "    else:\n",
    "        hours = row['intubation_hr']\n",
    "    rows = generate_before_weaning_rows(stay_id, hours)\n",
    "    charttime_template_df = pd.concat([charttime_template_df, pd.DataFrame(rows)], ignore_index=True)\n",
    "charttime_template_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ventilator mode group mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_ventilator_mode(ventilator_mode):\n",
    "    complete_support = [\"PRVC/AC\", \"PCV+Assist\", \"PCV+\", \"MMV/AutoFlow\", \"APRV\", \"CMV/AutoFlow\",\n",
    "                        \"CMV\", \"PRES/AC (PCAC)\", \"PRES/AC\", \"APV (cmv)\", \"PRVC/SIMV (=aprv)\", \"PRVC/SIMV\", \"MMV\",\n",
    "                        \"VOL/AC\", \"APRV/Biphasic+ApnVol\", \"APRV/Biphasic+ApnPress\", \"(S) CMV\",\n",
    "                        \"P-CMV\", \"CMV/ASSIST\", \"MMV/PSV/AutoFlow\", \"CMV/ASSIST/AutoFlow\"]\n",
    "\n",
    "    partial_support = [\"SIMV/PSV/AutoFlow\", \"SIMV/PRES\", \"SIMV/PSV\", \"SIMV/AutoFlow\", \"SIMV/VOL\",\n",
    "                       \"SIMV\", \"SYNCHRON MASTER\", \"SYNCHRON SLAVE\"]\n",
    "\n",
    "    minimal_support = [\"CPAP/PSV+ApnVol\", \"CPAP/PSV+Apn TCPL\", \"CPAP/PPS\", \"PCV+/PSV\", \"Apnea Ventilation\", \"CPAP\",\n",
    "                       \"MMV/PSV\", \"SPONT\", \"CPAP/PSV+ApnPres\", \"Ambient\", \"CPAP/PSV+Apn TCPL(time cycle pressure limit)\",\n",
    "                       \"null\", \"PSV/SBT\", \"Standby\", \"CPAP/PSV\"]\n",
    "\n",
    "    if ventilator_mode in complete_support:\n",
    "        return \"Complete Support\"\n",
    "    elif ventilator_mode in partial_support:\n",
    "        return \"Partial Support\"\n",
    "    elif ventilator_mode in minimal_support:\n",
    "        return \"Minimal Support\"\n",
    "    else:\n",
    "        return \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_settings_df['ventilator_mode_group'] = ventilator_settings_df['ventilator_mode'].apply(categorize_ventilator_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ventilator_settings before_weaning_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventilator_settings_hr_df = pd.merge(cohort_df, ventilator_settings_df, on=['stay_id', 'subject_id'])\n",
    "ventilator_settings_hr_df['charttime'] = pd.to_datetime(ventilator_settings_hr_df['charttime'])\n",
    "ventilator_settings_hr_df['endtime'] = pd.to_datetime(ventilator_settings_hr_df['endtime'])\n",
    "ventilator_settings_hr_df['starttime'] = pd.to_datetime(ventilator_settings_hr_df['starttime'])\n",
    "ventilator_settings_hr_df['before_weaning_hr'] = ((ventilator_settings_hr_df['endtime'] - ventilator_settings_hr_df['charttime']).dt.total_seconds() / 3600).astype(int)\n",
    "ventilator_settings_hr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge ventilator settings charttime evnets into template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join on stay_id and before_weaning_hr\n",
    "charttime_template_vese_df = pd.merge(charttime_template_df, ventilator_settings_hr_df.drop(columns=['charttime']), on=['stay_id', 'before_weaning_hr'], how='left')\n",
    "charttime_template_vese_df\n",
    "# Filter rows where before_weaning_hr from ventilator_settings_hr_df does not appear in charttime_template_df\n",
    "# filtered_df = charttime_template_vese_df.dropna(subset=['subject_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vitalsign before_weaning_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitalsign_hr_df = pd.merge(cohort_df, vitalsign_df, on=['stay_id', 'subject_id'])\n",
    "vitalsign_hr_df['charttime'] = pd.to_datetime(vitalsign_hr_df['charttime'])\n",
    "vitalsign_hr_df['endtime'] = pd.to_datetime(vitalsign_hr_df['endtime'])\n",
    "vitalsign_hr_df['starttime'] = pd.to_datetime(vitalsign_hr_df['starttime'])\n",
    "vitalsign_hr_df['before_weaning_hr'] = ((vitalsign_hr_df['endtime'] - vitalsign_hr_df['charttime']).dt.total_seconds() / 3600).astype(int)\n",
    "vitalsign_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vitalsign_gcs_hr_df = pd.merge(cohort_df, vitalsign_gcs_df, on=['stay_id', 'subject_id'])\n",
    "vitalsign_gcs_hr_df['charttime'] = pd.to_datetime(vitalsign_gcs_hr_df['charttime'])\n",
    "vitalsign_gcs_hr_df['endtime'] = pd.to_datetime(vitalsign_gcs_hr_df['endtime'])\n",
    "vitalsign_gcs_hr_df['starttime'] = pd.to_datetime(vitalsign_gcs_hr_df['starttime'])\n",
    "vitalsign_gcs_hr_df['before_weaning_hr'] = ((vitalsign_gcs_hr_df['endtime'] - vitalsign_gcs_hr_df['charttime']).dt.total_seconds() / 3600).astype(int)\n",
    "vitalsign_gcs_hr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge vitalsign charttime evnets into template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join on stay_id and before_weaning_hr\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    charttime_template_vese_visi_df = pd.merge(charttime_template_vese_df, vitalsign_hr_df.drop(columns=['charttime', 'starttime', 'endtime', 'intubation_hr', 'intubation_hr_add_4hr']), on=['stay_id', 'before_weaning_hr', 'subject_id'], how='left')\n",
    "    charttime_template_vese_visi_df = pd.merge(charttime_template_vese_visi_df, vitalsign_gcs_hr_df.drop(columns=['charttime', 'starttime', 'endtime', 'intubation_hr', 'intubation_hr_add_4hr']), on=['stay_id', 'before_weaning_hr', 'subject_id'], how='left')\n",
    "else:\n",
    "    charttime_template_vese_visi_df = pd.merge(charttime_template_vese_df, vitalsign_hr_df.drop(columns=['charttime', 'starttime', 'endtime', 'intubation_hr']), on=['stay_id', 'before_weaning_hr', 'subject_id'], how='left')\n",
    "    charttime_template_vese_visi_df = pd.merge(charttime_template_vese_visi_df, vitalsign_gcs_hr_df.drop(columns=['charttime', 'starttime', 'endtime', 'intubation_hr']), on=['stay_id', 'before_weaning_hr', 'subject_id'], how='left')\n",
    "charttime_template_vese_visi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_df[80:140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add RSBI and minute_ventilation, need to use the resp_rate from vitalsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_df['RSBI'] = charttime_template_vese_visi_df['resp_rate'] / (charttime_template_vese_visi_df['tidal_volume_observed'] * 0.001)\n",
    "charttime_template_vese_visi_df['minute_ventilation'] = charttime_template_vese_visi_df['resp_rate'] * (charttime_template_vese_visi_df['tidal_volume_observed'] * 0.001)\n",
    "charttime_template_vese_visi_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_df[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick max value for stay_id and before_weaning_hr have multiple rows\n",
    "WARNING: this code cell run 92mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_agg(series):\n",
    "#     non_nan_values = series.dropna().unique()\n",
    "#     if len(non_nan_values) == 1:\n",
    "#         return non_nan_values[0]\n",
    "#     elif len(non_nan_values) > 1:\n",
    "#         return non_nan_values.max()\n",
    "#     else:\n",
    "#         return np.nan\n",
    "\n",
    "# # Group by 'stay_id' and 'before_weaning_hr' and apply the custom aggregation function\n",
    "# if first_time_flag:\n",
    "#     charttime_template_vese_visi_hr_df = charttime_template_vese_visi_df.groupby(['stay_id', 'before_weaning_hr']).agg(custom_agg).reset_index()\n",
    "#     charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pick most severe value for stay_id and before_weaning_hr have multiple rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def agg_heart_rate(x):\n",
    "    arr = x.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    below = arr[arr < 60]\n",
    "    above = arr[arr > 130]\n",
    "    if len(above) > 0:\n",
    "        return above.max()\n",
    "    elif len(below) > 0:\n",
    "        return below.min()\n",
    "    else:\n",
    "        return np.median(arr)\n",
    "\n",
    "def agg_resp_rate(x):\n",
    "    arr = x.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    below = arr[arr < 12]\n",
    "    above = arr[arr > 30]\n",
    "    if len(above) > 0:\n",
    "        return above.max()\n",
    "    elif len(below) > 0:\n",
    "        return below.min()\n",
    "    else:\n",
    "        return np.median(arr)\n",
    "\n",
    "def agg_spo2(x):\n",
    "    arr = x.dropna()\n",
    "    arr = arr[arr > 0]\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.min()\n",
    "\n",
    "def agg_max(x):\n",
    "    arr = x.dropna()\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.max()\n",
    "\n",
    "def agg_sbp(x):\n",
    "    arr = x.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    below = arr[arr < 90]\n",
    "    above = arr[arr > 160]\n",
    "    if len(above) > 0:\n",
    "        return above.max()\n",
    "    elif len(below) > 0:\n",
    "        return below.min()\n",
    "    else:\n",
    "        return np.median(arr)\n",
    "\n",
    "def agg_mbp(x):\n",
    "    arr = x.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    below = arr[arr < 70]\n",
    "    above = arr[arr > 130]\n",
    "    if len(above) > 0:\n",
    "        return above.max()\n",
    "    elif len(below) > 0:\n",
    "        return below.min()\n",
    "    else:\n",
    "        return np.median(arr)\n",
    "\n",
    "def agg_dbp(x):\n",
    "    arr = x.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    below = arr[arr < 70]\n",
    "    above = arr[arr > 130]\n",
    "    if len(above) > 0:\n",
    "        return above.max()\n",
    "    elif len(below) > 0:\n",
    "        return below.min()\n",
    "    else:\n",
    "        return np.median(arr)\n",
    "\n",
    "def agg_min(x):\n",
    "    arr = x.dropna()\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.min()\n",
    "\n",
    "def agg_rsbi(x):\n",
    "    arr = x.dropna()\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.max()\n",
    "\n",
    "def agg_minute_ventilation(x):\n",
    "    arr = x.dropna()\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.min()\n",
    "\n",
    "# For columns not listed, use first non-null value\n",
    "def agg_first(x):\n",
    "    arr = x.dropna()\n",
    "    if len(arr) == 0:\n",
    "        return np.nan\n",
    "    return arr.iloc[0]\n",
    "\n",
    "agg_dict = {\n",
    "    'subject_id': agg_first,\n",
    "    'starttime': agg_first,\n",
    "    'endtime': agg_first,\n",
    "    'intubation_hr': agg_first,\n",
    "    'peep': agg_max,\n",
    "    'fio2': agg_max,\n",
    "    'tidal_volume_observed': agg_max,\n",
    "    'tidal_volume_set': agg_max,\n",
    "    'respiratory_rate_set': agg_max,\n",
    "    'plateau_pressure': agg_max,\n",
    "    'ventilator_mode': agg_first,\n",
    "    'ventilator_mode_group': agg_first,\n",
    "    'heart_rate': agg_heart_rate,\n",
    "    'resp_rate': agg_resp_rate,\n",
    "    'sbp': agg_sbp,\n",
    "    'dbp': agg_dbp,\n",
    "    'mbp': agg_mbp,\n",
    "    'spo2': agg_spo2,\n",
    "    'gcs': agg_min,\n",
    "    'RSBI': agg_rsbi,\n",
    "    'minute_ventilation': agg_minute_ventilation,\n",
    "}\n",
    "\n",
    "if first_time_flag:\n",
    "    charttime_template_vese_visi_hr_df = charttime_template_vese_visi_df.groupby(['stay_id', 'before_weaning_hr']).agg(agg_dict).reset_index()\n",
    "    charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    charttime_template_vese_visi_hr_df = charttime_template_vese_visi_hr_df.sort_values(by=['stay_id', 'before_weaning_hr'], ascending=[True, False])\n",
    "    charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    charttime_template_vese_visi_hr_df.to_csv(f\"{prefix_path}/charttime_template_vese_visi_hr.csv\")\n",
    "else:\n",
    "    charttime_template_vese_visi_hr_df = pd.read_csv(f\"{prefix_path}/charttime_template_vese_visi_hr.csv\")\n",
    "charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "- baseline_preprocess_df: don't needed\n",
    "- charttime_template_vese_visi_hr_df:\n",
    "    - based on Tukey's fences for outlier detection, which are defines 'non outlier' data as everything in the range ``[(first quartile - 1.5 IQR), (third quartile + 1.5 IQR)]\n",
    "    - based on textbook and paper, we get the reasonable range for each variables\n",
    "    - we choose the looser one as bound to exclude the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [MIT reference](https://emergency-vent.mit.edu/clinical/key-ventilation-specifications/)\n",
    "\n",
    "PEEP (Positive End-Expiratory Pressure): 5–20 cmH2O\n",
    "\n",
    "Reference: \"Mechanical Ventilation: Clinical Applications and Pathophysiology\" by Arthur S. Slutsky and Laurent Brochard, which suggests a typical PEEP range of 5-20 cmH2O for mechanically ventilated patients.\n",
    "FiO2 (Fraction of Inspired Oxygen): 21–100%\n",
    "\n",
    "Reference: Standard clinical practice guidelines for mechanical ventilation typically suggest a FiO2 range of 21–100% to maintain adequate oxygenation.\n",
    "Tidal Volume Observed and Tidal Volume Set: 200–800 mL\n",
    "\n",
    "Reference: \"Mechanical Ventilation\" by David C. Shelledy and Jay I. Peters, which indicates that the typical range for tidal volume is between 6-8 mL/kg of ideal body weight, translating to approximately 200-800 mL for most adults.\n",
    "Respiratory Rate Set: 6–40 breaths/min\n",
    "\n",
    "Reference: \"Pilbeam's Mechanical Ventilation: Physiological and Clinical Applications\" by J.M. Cairo and D.C. Pilbeam, which mentions a typical range of 6–40 breaths/min for ventilator settings.\n",
    "Plateau Pressure: 10–35 cmH2O\n",
    "\n",
    "Reference: \"The Principles and Practice of Mechanical Ventilation\" by Martin J. Tobin, which states that plateau pressures should ideally be kept below 30-35 cmH2O to prevent ventilator-induced lung injury.\n",
    "Heart Rate: 40–180 beats/min\n",
    "\n",
    "Reference: \"Harrison's Principles of Internal Medicine\" by J. Larry Jameson, et al., which outlines normal and critical ranges for heart rates in clinical settings.\n",
    "Respiratory Rate: 8–30 breaths/min\n",
    "\n",
    "Reference: \"Goldman-Cecil Medicine\" by Lee Goldman and Andrew I. Schafer, which suggests typical clinical ranges for respiratory rates.\n",
    "Systolic Blood Pressure (SBP): 70–200 mmHg\n",
    "\n",
    "Reference: \"Critical Care Medicine: Principles of Diagnosis and Management in the Adult\" by Joseph E. Parrillo and R. Phillip Dellinger, which provides clinical ranges for blood pressure.\n",
    "Diastolic Blood Pressure (DBP): 40–120 mmHg\n",
    "\n",
    "Reference: Same as SBP reference above.\n",
    "Mean Blood Pressure (MBP): 50–150 mmHg\n",
    "\n",
    "Reference: Same as SBP reference above.\n",
    "SpO2 (Oxygen Saturation): 80–100%\n",
    "\n",
    "Reference: Clinical guidelines for oxygen therapy generally recommend maintaining SpO2 levels between 80-100%.\n",
    "GCS (Glasgow Coma Scale): 3–15\n",
    "\n",
    "Reference: Standard clinical use of the Glasgow Coma Scale, which ranges from 3 (deep unconsciousness) to 15 (fully alert).\n",
    "RSBI (Rapid Shallow Breathing Index): 0–100\n",
    "\n",
    "Reference: \"Mechanical Ventilation\" by David C. Shelledy and Jay I. Peters, which describes RSBI values used for weaning patients from mechanical ventilation.\n",
    "Minute Ventilation: 2–20 L/min\n",
    "\n",
    "Reference: \"The Principles and Practice of Mechanical Ventilation\" by Martin J. Tobin, which outlines typical minute ventilation ranges for adults.\n",
    "These references provide the standard guidelines and ranges used in clinical practice to ensure patient safety and efficacy of mechanical ventilation settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the bounds and set outliers to NaN\n",
    "def set_outliers_to_nan(df, column, guidelines):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    data_lower_bound = Q1 - 1.5 * IQR\n",
    "    data_upper_bound = Q3 + 1.5 * IQR\n",
    "    guideline_lower_bound = guidelines[column]['lower']\n",
    "    guideline_upper_bound = guidelines[column]['upper']\n",
    "    \n",
    "    # Determine the stricter bounds\n",
    "    lower_bound = min(data_lower_bound, guideline_lower_bound)\n",
    "    upper_bound = max(data_upper_bound, guideline_upper_bound)\n",
    "    \n",
    "    # Apply the bounds to the column, setting outliers to NaN\n",
    "    df[column] = df[column].apply(lambda x: x if pd.notnull(x) and lower_bound <= x <= upper_bound else np.nan)\n",
    "\n",
    "# Dictionary with guidelines for each variable\n",
    "guidelines = {\n",
    "    'peep': {'lower': 0, 'upper': 20},\n",
    "    'fio2': {'lower': 21, 'upper': 100},\n",
    "    'tidal_volume_observed': {'lower': 200, 'upper': 800},\n",
    "    'tidal_volume_set': {'lower': 200, 'upper': 800},\n",
    "    'respiratory_rate_set': {'lower': 6, 'upper': 40},\n",
    "    'plateau_pressure': {'lower': 10, 'upper': 35},\n",
    "    'heart_rate': {'lower': 40, 'upper': 180},\n",
    "    'resp_rate': {'lower': 8, 'upper': 30},\n",
    "    'sbp': {'lower': 70, 'upper': 200},\n",
    "    'dbp': {'lower': 40, 'upper': 120},\n",
    "    'mbp': {'lower': 50, 'upper': 150},\n",
    "    'spo2': {'lower': 80, 'upper': 100},\n",
    "    'gcs': {'lower': 3, 'upper': 15},\n",
    "    'RSBI': {'lower': 0, 'upper': 100},\n",
    "    'minute_ventilation': {'lower': 2, 'upper': 20}\n",
    "}\n",
    "\n",
    "# List of columns to check for outliers\n",
    "columns_to_check = [\n",
    "    'peep', 'fio2', 'tidal_volume_observed', 'tidal_volume_set',\n",
    "    'respiratory_rate_set', 'plateau_pressure', 'heart_rate', 'resp_rate',\n",
    "    'sbp', 'dbp', 'mbp', 'spo2', 'gcs', 'RSBI', 'minute_ventilation'\n",
    "]\n",
    "\n",
    "# Copy the dataframe\n",
    "charttime_template_vese_visi_hr_without_outliers_df = charttime_template_vese_visi_hr_df.copy(deep=True)\n",
    "\n",
    "# Apply the function to each column\n",
    "for col in columns_to_check:\n",
    "    set_outliers_to_nan(charttime_template_vese_visi_hr_without_outliers_df, col, guidelines)\n",
    "\n",
    "charttime_template_vese_visi_hr_without_outliers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_df['ventilator_mode_group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_df[[\"ventilator_mode_group\"]].isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_df[:60]\n",
    "# charttime_template_vese_visi_hr_without_outliers_df[60:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing value\n",
    "- baseline\n",
    "- charttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "- weight & height -> KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preprocess_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fill_missing_df = baseline_preprocess_df.copy(deep=True)\n",
    "# Select columns for imputation\n",
    "columns_to_impute = ['age', 'weight', 'height', 'gender_F', 'gender_M']\n",
    "\n",
    "# Separate the data to impute and the rest of the data\n",
    "impute_data = baseline_fill_missing_df[columns_to_impute]\n",
    "\n",
    "# Create KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Apply KNN Imputer\n",
    "imputed_data = imputer.fit_transform(impute_data)\n",
    "\n",
    "# Assign imputed values back to the DataFrame\n",
    "baseline_fill_missing_df[columns_to_impute] = imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_fill_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charttime\n",
    "- ffill then bfill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first take a look at the miss distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Calculate NaN percentage for each column\n",
    "nan_percentage = charttime_template_vese_visi_hr_without_outliers_df.isna().mean() * 100\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "nan_analysis = pd.DataFrame({\n",
    "    'Feature': nan_percentage.index,\n",
    "    'NaN Count': charttime_template_vese_visi_hr_without_outliers_df.isna().sum(),\n",
    "    'NaN Percentage': nan_percentage,\n",
    "    'Non-NaN Count': charttime_template_vese_visi_hr_without_outliers_df.count(),\n",
    "})\n",
    "\n",
    "# Sort by NaN percentage (descending)\n",
    "nan_analysis = nan_analysis.sort_values('NaN Percentage', ascending=False)\n",
    "\n",
    "# Print the results\n",
    "print(\"Missing Value Analysis:\")\n",
    "print(nan_analysis)\n",
    "\n",
    "# Visualize NaN percentages\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(nan_analysis['Feature'], nan_analysis['NaN Percentage'], color='skyblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('NaN Percentage (%)')\n",
    "plt.title('Percentage of Missing Values by Feature')\n",
    "plt.axhline(y=50, color='r', linestyle='--', label='50% Missing')\n",
    "plt.axhline(y=20, color='orange', linestyle='--', label='20% Missing')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap to visualize missing values\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(charttime_template_vese_visi_hr_without_outliers_df.isna(), \n",
    "            cbar=False, \n",
    "            yticklabels=False,\n",
    "            cmap='viridis')\n",
    "plt.title('Missing Values Heatmap (Yellow = Missing)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values within each stay_id\n",
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df = charttime_template_vese_visi_hr_without_outliers_df.copy(deep=True)\n",
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df = charttime_template_vese_visi_hr_without_outliers_fill_missing_df.groupby('stay_id').apply(lambda group: group.ffill().bfill())\n",
    "# Reset the index to avoid any issues caused by groupby\n",
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df = charttime_template_vese_visi_hr_without_outliers_fill_missing_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_count_mode_change_df = charttime_template_vese_visi_hr_without_outliers_fill_missing_df.copy(deep=True)\n",
    "# Fill NaNs with forward fill and backward fill\n",
    "target = \"ventilator_mode_group\"\n",
    "# charttime_template_vese_visi_hr_without_outliers_count_mode_change_df[f'{target}'] = charttime_template_vese_visi_hr_without_outliers_count_mode_change_df.groupby('stay_id')[f'{target}'].ffill().bfill()\n",
    "\n",
    "# Function to count changes in {target} within each stay_id\n",
    "def count_changes(group):\n",
    "    # group[f'{target}'] = group[f'{target}'].ffill().bfill()\n",
    "    changes = (group[f'{target}'] != group[f'{target}'].shift(1)).sum() - 1\n",
    "    return changes\n",
    "\n",
    "# Group by stay_id and count changes\n",
    "change_counts = charttime_template_vese_visi_hr_without_outliers_count_mode_change_df.groupby('stay_id').apply(count_changes)\n",
    "\n",
    "# Calculate the average number of changes\n",
    "average_changes = change_counts.mean()\n",
    "\n",
    "# Display the result\n",
    "print(f'Average number of changes in {target} per stay_id: {average_changes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RSBI and minute_ventilation calculated by the filled result of resp_rate and tidal_volume_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df['RSBI'] = charttime_template_vese_visi_hr_without_outliers_fill_missing_df['resp_rate'] / (charttime_template_vese_visi_hr_without_outliers_fill_missing_df['tidal_volume_observed'] * 0.001)\n",
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df['minute_ventilation'] = charttime_template_vese_visi_hr_without_outliers_fill_missing_df['resp_rate'] * (charttime_template_vese_visi_hr_without_outliers_fill_missing_df['tidal_volume_observed'] * 0.001)\n",
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charttime_template_vese_visi_hr_without_outliers_fill_missing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate ground truth label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"eICU\":\n",
    "    # Create a deep copy of ground_truth_df\n",
    "    ground_truth_with_label_df = ground_truth_df.copy(deep=True)\n",
    "    \n",
    "    # Add new columns with default values of 0\n",
    "    ground_truth_with_label_df['dead_time_gap_hr'] = 0\n",
    "    ground_truth_with_label_df['reintubation_time_gap_hr'] = 0\n",
    "    \n",
    "    # Create label column based on died_in_unit flag\n",
    "    # 1 = successful weaning (patient didn't die in unit)\n",
    "    # 0 = failed weaning (patient died in unit)\n",
    "    ground_truth_with_label_df['label'] = ground_truth_with_label_df['died_in_unit'].apply(lambda x: 0 if x == True else 1)\n",
    "    \n",
    "    # Alternative formulation if you prefer:\n",
    "    # ground_truth_with_label_df['label'] = (~ground_truth_with_label_df['died_in_unit']).astype(int)\n",
    "    \n",
    "    print(\"eICU data processing complete:\")\n",
    "    print(f\"Label distribution: {ground_truth_with_label_df['label'].value_counts()}\")\n",
    "else:\n",
    "    # Convert date columns to datetime\n",
    "    ground_truth_with_label_df = ground_truth_df.copy(deep=True)\n",
    "    ground_truth_with_label_df['endtime'] = pd.to_datetime(ground_truth_with_label_df['endtime'])\n",
    "    ground_truth_with_label_df['dod'] = pd.to_datetime(ground_truth_with_label_df['dod'])\n",
    "\n",
    "    # Calculate dead_time_gap_hr\n",
    "    ground_truth_with_label_df['dead_time_gap_hr'] = (ground_truth_with_label_df['dod'] - ground_truth_with_label_df['endtime']).dt.total_seconds() / 3600\n",
    "\n",
    "    # Generate label column\n",
    "    conditions = [\n",
    "        (ground_truth_with_label_df['reintubation_time_gap_hr'] < 48),\n",
    "        (ground_truth_with_label_df['dead_time_gap_hr'] < 48)\n",
    "    ]\n",
    "\n",
    "    ground_truth_with_label_df['label'] = 1\n",
    "    ground_truth_with_label_df.loc[conditions[0] | conditions[1], 'label'] = 0\n",
    "ground_truth_with_label_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine baseline with charttime and ground truth\n",
    "- baseline_fill_missing_df\n",
    "- charttime_template_vese_visi_hr_without_outliers_fill_missing_df\n",
    "- ground_truth_with_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"eICU\":\n",
    "    baseline_fill_missing_df = baseline_fill_missing_df.drop(columns=['starttime', 'endtime'])\n",
    "baseline_charttime_df = pd.merge(charttime_template_vese_visi_hr_without_outliers_fill_missing_df, baseline_fill_missing_df.drop(columns=['subject_id']), on=['stay_id'])\n",
    "baseline_charttime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_df = pd.merge(baseline_charttime_df, ground_truth_with_label_df[[\"stay_id\", \"reintubation_time_gap_hr\", \"dead_time_gap_hr\", \"label\"]], on=['stay_id'])\n",
    "baseline_charttime_ground_truth_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    columns = [\n",
    "        'stay_id', 'before_weaning_hr', 'subject_id', 'intubation_hr', 'intubation_hr_add_4hr', \n",
    "        'peep', 'fio2', 'tidal_volume_observed', 'tidal_volume_set', 'respiratory_rate_set', \n",
    "        'plateau_pressure', 'heart_rate', 'resp_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'gcs', \n",
    "        'RSBI', 'minute_ventilation', 'age', 'weight', 'height', 'tobacco', 'race_grouped_ASIAN', \n",
    "        'race_grouped_BLACK', 'race_grouped_HISPANIC', 'race_grouped_OTHERS', 'race_grouped_WHITE', \n",
    "        'gender_F', 'gender_M', 'reintubation_time_gap_hr', 'dead_time_gap_hr', 'label'\n",
    "    ]\n",
    "else:\n",
    "    columns = [\n",
    "        'stay_id', 'before_weaning_hr', 'subject_id', 'intubation_hr',\n",
    "        'peep', 'fio2', 'tidal_volume_observed', 'tidal_volume_set', 'respiratory_rate_set', \n",
    "        'plateau_pressure', 'heart_rate', 'resp_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'gcs', \n",
    "        'RSBI', 'minute_ventilation', 'age', 'weight', 'height', 'tobacco', 'race_grouped_ASIAN', \n",
    "        'race_grouped_BLACK', 'race_grouped_HISPANIC', 'race_grouped_OTHERS', 'race_grouped_WHITE', \n",
    "        'gender_F', 'gender_M', 'reintubation_time_gap_hr', 'dead_time_gap_hr', 'label'\n",
    "    ]\n",
    "\n",
    "# Specify categorical columns\n",
    "categorical = [\n",
    "    'tobacco', 'race_grouped_ASIAN', 'race_grouped_BLACK', 'race_grouped_HISPANIC', \n",
    "    'race_grouped_OTHERS', 'race_grouped_WHITE', 'gender_F', 'gender_M', 'label'\n",
    "]\n",
    "\n",
    "# Create TableOne\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    table = TableOne(baseline_charttime_ground_truth_df, columns=columns, categorical=categorical, nonnormal=['intubation_hr', 'intubation_hr_add_4hr'])\n",
    "else:\n",
    "    table = TableOne(baseline_charttime_ground_truth_df, columns=columns, categorical=categorical, nonnormal=['intubation_hr'])\n",
    "\n",
    "# Display TableOne\n",
    "print(table.tabulate(tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with missing values in the specified columns\n",
    "if DATA_SOURCE == \"eICU\" or DATA_SOURCE == \"MIMIC-III\":\n",
    "    baseline_charttime_ground_truth_drop_missing_df = baseline_charttime_ground_truth_df.dropna(subset=selected_columns)\n",
    "else:\n",
    "    baseline_charttime_ground_truth_drop_missing_df = baseline_charttime_ground_truth_df.dropna(subset=selected_columns) # ['peep', 'tidal_volume_set', 'respiratory_rate_set', 'plateau_pressure', 'RSBI', 'gcs']\n",
    "print(f\"before: {len(baseline_charttime_ground_truth_df['stay_id'].unique())}\")\n",
    "print(f\"after: {len(baseline_charttime_ground_truth_drop_missing_df['stay_id'].unique())}\")\n",
    "print(f\"drop: {len(baseline_charttime_ground_truth_df['stay_id'].unique()) - len(baseline_charttime_ground_truth_drop_missing_df['stay_id'].unique())}\")\n",
    "print(f\"ratio: {(len(baseline_charttime_ground_truth_df['stay_id'].unique()) - len(baseline_charttime_ground_truth_drop_missing_df['stay_id'].unique())) / len(baseline_charttime_ground_truth_df['stay_id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_missing_rate(df, features):\n",
    "    total_stays = len(df['stay_id'].unique())\n",
    "    missing_counts = {}\n",
    "    \n",
    "    for feature in features:\n",
    "        # Get stays where the feature is entirely missing\n",
    "        feature_missing_stays = df.groupby('stay_id')[feature].apply(lambda x: x.isna().all())\n",
    "        stays_missing_feature = feature_missing_stays[feature_missing_stays].index.tolist()\n",
    "        \n",
    "        missing_counts[feature] = {\n",
    "            'num_stays_missing': len(stays_missing_feature),\n",
    "            'pct_stays_missing': len(stays_missing_feature) / total_stays * 100\n",
    "        }\n",
    "    \n",
    "    # Sort by missing rate (highest to lowest)\n",
    "    sorted_features = sorted(missing_counts.items(), key=lambda x: x[1]['pct_stays_missing'], reverse=True)\n",
    "    \n",
    "    print(f\"Total unique stay_ids: {total_stays}\")\n",
    "    print(\"\\nMissing rates by feature (feature totally absent for entire stay):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Feature':<25} {'Stays Missing':<15} {'% of Total Stays':<20}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for feature, stats in sorted_features:\n",
    "        print(f\"{feature:<25} {stats['num_stays_missing']:<15} {stats['pct_stays_missing']:.2f}%\")\n",
    "    \n",
    "    return missing_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which features are causing most of the drops\n",
    "missing_rates = analyze_feature_missing_rate(baseline_charttime_ground_truth_df, selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    columns = [\n",
    "        'stay_id', 'before_weaning_hr', 'subject_id', 'intubation_hr', 'intubation_hr_add_4hr', \n",
    "        'peep', 'fio2', 'tidal_volume_observed', 'tidal_volume_set', 'respiratory_rate_set', \n",
    "        'plateau_pressure', 'heart_rate', 'resp_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'gcs', \n",
    "        'RSBI', 'minute_ventilation', 'age', 'weight', 'height', 'tobacco', 'race_grouped_ASIAN', \n",
    "        'race_grouped_BLACK', 'race_grouped_HISPANIC', 'race_grouped_OTHERS', 'race_grouped_WHITE', \n",
    "        'gender_F', 'gender_M', 'reintubation_time_gap_hr', 'dead_time_gap_hr', 'ventilator_mode_group', 'label'\n",
    "    ]\n",
    "else:\n",
    "    columns = [\n",
    "        'stay_id', 'before_weaning_hr', 'subject_id', 'intubation_hr', \n",
    "        'peep', 'fio2', 'tidal_volume_observed', 'tidal_volume_set', 'respiratory_rate_set', \n",
    "        'plateau_pressure', 'heart_rate', 'resp_rate', 'sbp', 'dbp', 'mbp', 'spo2', 'gcs', \n",
    "        'RSBI', 'minute_ventilation', 'age', 'weight', 'height', 'tobacco', 'race_grouped_ASIAN', \n",
    "        'race_grouped_BLACK', 'race_grouped_HISPANIC', 'race_grouped_OTHERS', 'race_grouped_WHITE', \n",
    "        'gender_F', 'gender_M', 'reintubation_time_gap_hr', 'dead_time_gap_hr', 'ventilator_mode_group', 'label'\n",
    "    ]\n",
    "\n",
    "# Specify categorical columns\n",
    "categorical = [\n",
    "    'tobacco', 'race_grouped_ASIAN', 'race_grouped_BLACK', 'race_grouped_HISPANIC', \n",
    "    'race_grouped_OTHERS', 'race_grouped_WHITE', 'gender_F', 'gender_M', 'ventilator_mode_group', 'label'\n",
    "]\n",
    "\n",
    "# Create TableOne\n",
    "if EXTRA_4_HR_FLAG:\n",
    "    table = TableOne(baseline_charttime_ground_truth_drop_missing_df, columns=columns, categorical=categorical, nonnormal=['intubation_hr', 'intubation_hr_add_4hr'])\n",
    "else:\n",
    "    table = TableOne(baseline_charttime_ground_truth_drop_missing_df, columns=columns, categorical=categorical, nonnormal=['intubation_hr', 'intubation_hr_add_4hr'])\n",
    "\n",
    "# Display TableOne\n",
    "print(table.tabulate(tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable rows trajectroy\n",
    "- baseline_charttime_ground_truth.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_charttime_ground_truth_drop_missing_df[\"stay_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    baseline_charttime_ground_truth_drop_missing_df.to_csv(f\"{prefix_path}/baseline_charttime_ground_truth.csv\", index=False)\n",
    "    \n",
    "    import json\n",
    "\n",
    "    # Select the columns to normalize\n",
    "    columns_to_normalize = baseline_charttime_ground_truth_drop_missing_df[[\"peep\", \"fio2\", \"tidal_volume_observed\", \"tidal_volume_set\", \"respiratory_rate_set\", \"plateau_pressure\", \"heart_rate\", \"resp_rate\", \"sbp\", \"dbp\", \"mbp\", \"spo2\", \"gcs\", \"RSBI\", \"minute_ventilation\", \"age\", \"weight\", \"height\" ]]\n",
    "\n",
    "    # Create a dictionary to store min and max values\n",
    "    min_max_dict = {}\n",
    "\n",
    "    # Calculate min and max for each column and store in the dictionary\n",
    "    for col in columns_to_normalize:\n",
    "        min_max_dict[col] = {\n",
    "            'min': baseline_charttime_ground_truth_drop_missing_df[col].min(),\n",
    "            'max': baseline_charttime_ground_truth_drop_missing_df[col].max()\n",
    "        }\n",
    "\n",
    "    # Save the dictionary to a file\n",
    "    with open(f'{prefix_path}/min_max_values.json', 'w') as f:\n",
    "        json.dump(min_max_dict, f)\n",
    "\n",
    "    print(\"Min and max values saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for ehrMGAN input format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update baseline_charttime_ground_truth.csv\n",
    "- version 1: death_time_gap_hr is calculate from the mimic-iv-hospital.patient dod\n",
    "- version 2: death_time_gap_hr is calculate from the mimic-iv-hospital.admission deathtime\n",
    "    - ground_truth.csv -> ground_truth_deathtime.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_SOURCE == \"eICU\":\n",
    "    baseline_charttime_ground_truth_df = pd.read_csv(f\"{prefix_path}/baseline_charttime_ground_truth.csv\")\n",
    "    ground_truth_deathtime_df = ground_truth_df.copy(deep=True)\n",
    "    ground_truth_deathtime_df['deathtime'] = ground_truth_df['endtime']\n",
    "elif DATA_SOURCE == \"MIMIC-IV\":\n",
    "    baseline_charttime_ground_truth_df = pd.read_csv(f\"{prefix_path}/baseline_charttime_ground_truth.csv\")\n",
    "    ground_truth_deathtime_df = pd.read_csv(f'{prefix_path}/ground_truth_deathtime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_deathtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_deathtime_df['endtime'] = pd.to_datetime(ground_truth_deathtime_df['endtime'])\n",
    "ground_truth_deathtime_df['deathtime'] = pd.to_datetime(ground_truth_deathtime_df['deathtime'])\n",
    "\n",
    "# Calculate dead_time_gap_hr\n",
    "ground_truth_deathtime_df['dead_time_gap_hr'] = (ground_truth_deathtime_df['deathtime'] - ground_truth_deathtime_df['endtime']).dt.total_seconds() / 3600\n",
    "\n",
    "# Display the result\n",
    "ground_truth_deathtime_df[[\"stay_id\", \"deathtime\", \"dead_time_gap_hr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_drop_dod_df = baseline_charttime_ground_truth_df.drop(columns=[\"dead_time_gap_hr\"])\n",
    "baseline_charttime_ground_truth_dead_time_df = baseline_charttime_ground_truth_drop_dod_df.merge(\n",
    "    ground_truth_deathtime_df[[\"stay_id\", \"deathtime\", \"dead_time_gap_hr\"]],\n",
    "    on=\"stay_id\",\n",
    "    how=\"left\"  # Use \"left\" join to keep all rows from the baseline DataFrame\n",
    ")\n",
    "baseline_charttime_ground_truth_dead_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_dead_time_df[baseline_charttime_ground_truth_dead_time_df[\"dead_time_gap_hr\"] < 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule of label (new rule)\n",
    "- dead:\n",
    "    - a → 0\t    dead before weaning: 74\n",
    "    - b → -1\tdead within 48hr after weaning: 925\n",
    "    - c → 1\t    no dead or reintubation within 48hr after weaning: 4691\n",
    "- reintubation:\n",
    "    - a → x\t    null\n",
    "    - b → -2\treintubation within 48hr after weaning: 467 (not sure used it or not)\n",
    "    - c → 1\t    same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_new_label_df = baseline_charttime_ground_truth_dead_time_df.drop(columns=[\"label\"])\n",
    "\n",
    "# Define conditions\n",
    "conditions = [\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'] >= 48) & (baseline_charttime_ground_truth_new_label_df['reintubation_time_gap_hr'] >= 48),\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'] >= 48) & (baseline_charttime_ground_truth_new_label_df['reintubation_time_gap_hr'].isna()),\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'].isna()) & (baseline_charttime_ground_truth_new_label_df['reintubation_time_gap_hr'] >= 48),\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'].isna()) & (baseline_charttime_ground_truth_new_label_df['reintubation_time_gap_hr'].isna()),\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'] <= 0),\n",
    "    (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'] > 0) & (baseline_charttime_ground_truth_new_label_df['dead_time_gap_hr'] < 48),\n",
    "    (baseline_charttime_ground_truth_new_label_df['reintubation_time_gap_hr'] < 48),\n",
    "]\n",
    "\n",
    "# Define corresponding label values\n",
    "choices = [1, 1, 1, 1, 0, -1, -2]\n",
    "\n",
    "# Apply the conditions\n",
    "baseline_charttime_ground_truth_new_label_df['label'] = np.select(conditions, choices, default=-3)\n",
    "baseline_charttime_ground_truth_new_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_new_label_df[baseline_charttime_ground_truth_new_label_df[\"label\"] == -2].groupby(\"stay_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stay_id_df = baseline_charttime_ground_truth_new_label_df.drop_duplicates(subset='subject_id', keep='first')\n",
    "# unique_stay_id_df = baseline_charttime_ground_truth_new_label_df.drop_duplicates(subset='stay_id', keep='first')\n",
    "unique_stay_id_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stay_id_df.groupby(\"label\").count()[\"stay_id\"] / unique_stay_id_df.groupby(\"label\").count()[\"stay_id\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "467+925+74+4691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_new_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    baseline_charttime_ground_truth_new_label_df.to_csv(f\"{prefix_path}/baseline_charttime_ground_truth_-2~1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label merge back to 0 and 1\n",
    "- Due to the down stream task, we still need to map the label -2 ~ 1 to 0 / 1\n",
    "- unique subject_id: 6157\n",
    "- unique stay_id: 6798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_df = pd.read_csv(f'{prefix_path}/baseline_charttime_ground_truth_-2~1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_drop_df = ground_truth_multi_stage_df.drop_duplicates(subset=['subject_id'], keep='first')\n",
    "ground_truth_multi_stage_drop_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_drop_df = ground_truth_multi_stage_df.drop_duplicates(subset=['stay_id'], keep='first')\n",
    "ground_truth_multi_stage_drop_df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map label -1 to 0\n",
    "ground_truth_multi_stage_df['label'] = ground_truth_multi_stage_df['label'].replace(-1, 0)\n",
    "# Remove rows with label -2\n",
    "ground_truth_multi_stage_without_reintubation_df = ground_truth_multi_stage_df[ground_truth_multi_stage_df['label'] != -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rewrite the original version baseline_charttime_ground_truth.csv based on the reintubation / die as neg, otherwise pos, 6157 distinct subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_df = pd.read_csv(f'{prefix_path}/baseline_charttime_ground_truth_-2~1.csv')\n",
    "ground_truth_multi_stage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_df['label'] = ground_truth_multi_stage_df['label'].replace(-1, 0)\n",
    "ground_truth_multi_stage_df['label'] = ground_truth_multi_stage_df['label'].replace(-2, 0)\n",
    "# first_time_flag = False\n",
    "if first_time_flag:\n",
    "    ground_truth_multi_stage_df.to_csv(f'{prefix_path}/baseline_charttime_ground_truth_with_reintubation_binary_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_multi_stage_df.drop_duplicates(subset='subject_id', keep='first').groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_time_flag = False\n",
    "if first_time_flag:\n",
    "    ground_truth_multi_stage_without_reintubation_df.to_csv(f\"{prefix_path}/baseline_charttime_ground_truth.csv\", index=False)\n",
    "first_time_flag = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate three csv files\n",
    "- fixed_rows_trajectory.csv: fixed length (e.g., 24hr, or 48hr) for each patients trajectory\n",
    "- var_rows_trajectory.csv: variable length for each patients trajectory\n",
    "- last_state_with_outcome.csv: last state variables with ground truth outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_drop_missing_df = pd.read_csv(f\"{prefix_path}/baseline_charttime_ground_truth.csv\")\n",
    "baseline_charttime_ground_truth_drop_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixed rows trajectory:\n",
    "- baseline_charttime_ground_truth_0_hr.csv\n",
    "- baseline_charttime_ground_truth_24_hr.csv\n",
    "- baseline_charttime_ground_truth_48_hr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_weaning_n_hr_list = [1, 24, 48]\n",
    "\n",
    "# Filter the DataFrame\n",
    "if first_time_flag:\n",
    "    for n_hr in before_weaning_n_hr_list:\n",
    "        baseline_charttime_ground_truth_n_hr_df = baseline_charttime_ground_truth_drop_missing_df[baseline_charttime_ground_truth_drop_missing_df['before_weaning_hr'] < n_hr]\n",
    "        baseline_charttime_ground_truth_n_hr_df.to_csv(f\"{prefix_path}/baseline_charttime_ground_truth_{n_hr}_hr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_n_hr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "48 * 6798"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ventilator_mode_group_change_transition.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new column with default value 0\n",
    "baseline_charttime_ground_truth_mode_change_df = baseline_charttime_ground_truth_df.copy(deep=True)\n",
    "baseline_charttime_ground_truth_mode_change_df['ventilator_mode_group_change'] = 0\n",
    "\n",
    "# Iterate over the DataFrame to set the ventilator_mode_group_change values\n",
    "for i in range(len(baseline_charttime_ground_truth_mode_change_df) - 1):\n",
    "    if baseline_charttime_ground_truth_mode_change_df.loc[i, 'stay_id'] == baseline_charttime_ground_truth_mode_change_df.loc[i + 1, 'stay_id']:\n",
    "        current_mode = baseline_charttime_ground_truth_mode_change_df.loc[i, 'ventilator_mode_group']\n",
    "        next_mode = baseline_charttime_ground_truth_mode_change_df.loc[i + 1, 'ventilator_mode_group']\n",
    "        \n",
    "        if current_mode == 'Minimal Support' and next_mode == 'Complete Support':\n",
    "            baseline_charttime_ground_truth_mode_change_df.at[i, 'ventilator_mode_group_change'] = -1\n",
    "        elif current_mode == 'Complete Support' and next_mode == 'Minimal Support':\n",
    "            baseline_charttime_ground_truth_mode_change_df.at[i, 'ventilator_mode_group_change'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_mode_change_subset_df = baseline_charttime_ground_truth_mode_change_df[baseline_charttime_ground_truth_mode_change_df[\"ventilator_mode_group_change\"] != 0]\n",
    "baseline_charttime_ground_truth_mode_change_subset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change ratio: around 2% transitions change ventilator mode group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_charttime_ground_truth_mode_change_subset_df) / len(baseline_charttime_ground_truth_mode_change_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worse_count = len(baseline_charttime_ground_truth_mode_change_df[baseline_charttime_ground_truth_mode_change_df[\"ventilator_mode_group_change\"] == -1])\n",
    "better_count = len(baseline_charttime_ground_truth_mode_change_df[baseline_charttime_ground_truth_mode_change_df[\"ventilator_mode_group_change\"] == 1])\n",
    "print(f'ventilator mode group change worse: {worse_count}')\n",
    "print(f'ventilator mode group change better: {better_count}')\n",
    "print(f\"{worse_count/(worse_count + better_count)} : {better_count/(worse_count + better_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_charttime_ground_truth_mode_change_subset_drop_missing_df = baseline_charttime_ground_truth_mode_change_subset_df.dropna(subset=['peep', 'tidal_volume_set', 'respiratory_rate_set', 'plateau_pressure', 'RSBI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_time_flag:\n",
    "    baseline_charttime_ground_truth_mode_change_subset_drop_missing_df.to_csv(f\"{prefix_path}/baseline_charttime_ground_truth_mode_change.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: for those ventilator settings mode change, maybe single hr transition is not enough, since it won't consider how \"stable\" of the patient state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for Cohort Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Data reading\n",
    "# ================================\n",
    "# Define data paths (update if needed)\n",
    "eICU_prefix_path = \"../data/eICU\"\n",
    "mimic_iii_prefix_path = \"../data/mimic_iii\"\n",
    "mimic_iv_prefix_path = \"../data/mimic_iv\"\n",
    "\n",
    "eICU_file = os.path.join(eICU_prefix_path, \"baseline_charttime_ground_truth.csv\")\n",
    "mimic_iv_file = os.path.join(mimic_iv_prefix_path, \"baseline_charttime_ground_truth.csv\")\n",
    "mimic_iii_file = os.path.join(mimic_iii_prefix_path, \"baseline_charttime_ground_truth.csv\")\n",
    "\n",
    "# Read dataframes\n",
    "eICU_df = pd.read_csv(eICU_file)\n",
    "mimic_iv_df = pd.read_csv(mimic_iv_file)\n",
    "mimic_iii_df = pd.read_csv(mimic_iii_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_iv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eICU_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def cohort_description(df, dataset_name):\n",
    "    \"\"\"\n",
    "    Generate cohort description for race, sepsis, ARDS, gender, and age.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Input DataFrame (MIMIC-IV or eICU)\n",
    "    dataset_name (str): Name of the dataset ('MIMIC-IV' or 'eICU')\n",
    "    \n",
    "    Returns:\n",
    "    dict: Summary statistics for the cohort\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary\n",
    "    results = {'Dataset': dataset_name}\n",
    "    \n",
    "    # Total number of stays\n",
    "    total_stays = df['stay_id'].nunique()\n",
    "    results['Total Stays'] = total_stays\n",
    "    \n",
    "    # Race distribution\n",
    "    race_columns = ['race_grouped_ASIAN', 'race_grouped_BLACK', 'race_grouped_HISPANIC', \n",
    "                    'race_grouped_OTHERS', 'race_grouped_WHITE']\n",
    "    race_counts = {}\n",
    "    for col in race_columns:\n",
    "        race_name = col.split('_')[-1].capitalize()\n",
    "        count = df[df[col] == True]['stay_id'].nunique()\n",
    "        percentage = (count / total_stays * 100) if total_stays > 0 else 0\n",
    "        race_counts[race_name] = {'Count': count, 'Percentage': round(percentage, 2)}\n",
    "    results['Race Distribution'] = race_counts\n",
    "    \n",
    "    # Sepsis distribution\n",
    "    sepsis_count = df[df['sepsis'] == 1]['stay_id'].nunique()\n",
    "    sepsis_percentage = (sepsis_count / total_stays * 100) if total_stays > 0 else 0\n",
    "    results['Sepsis'] = {'Count': sepsis_count, 'Percentage': round(sepsis_percentage, 2)}\n",
    "    \n",
    "    # ARDS distribution\n",
    "    ards_count = df[df['ards'] == 1]['stay_id'].nunique()\n",
    "    ards_percentage = (ards_count / total_stays * 100) if total_stays > 0 else 0\n",
    "    results['ARDS'] = {'Count': ards_count, 'Percentage': round(ards_percentage, 2)}\n",
    "    \n",
    "    # Gender distribution\n",
    "    gender_counts = {}\n",
    "    gender_columns = ['gender_F', 'gender_M'] + (['gender_Unknown'] if 'gender_Unknown' in df.columns else [])\n",
    "    for col in gender_columns:\n",
    "        gender_name = col.split('_')[-1].capitalize()\n",
    "        count = df[df[col] == True]['stay_id'].nunique() if col == 'gender_Unknown' else df[df[col] == 1.0]['stay_id'].nunique()\n",
    "        percentage = (count / total_stays * 100) if total_stays > 0 else 0\n",
    "        gender_counts[gender_name] = {'Count': count, 'Percentage': round(percentage, 2)}\n",
    "    results['Gender Distribution'] = gender_counts\n",
    "    \n",
    "    # Age distribution\n",
    "    age_stats = df.groupby('stay_id')['age'].first().agg(['mean', 'std']).to_dict()\n",
    "    results['Age'] = {\n",
    "        'Mean': round(age_stats['mean'], 2) if not np.isnan(age_stats['mean']) else 0,\n",
    "        'Std': round(age_stats['std'], 2) if not np.isnan(age_stats['std']) else 0\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_cohort_summary(mimic_results, eicu_results):\n",
    "    \"\"\"\n",
    "    Print cohort description in a formatted table-like structure.\n",
    "    \n",
    "    Parameters:\n",
    "    mimic_results (dict): Summary statistics for MIMIC-IV\n",
    "    eicu_results (dict): Summary statistics for eICU\n",
    "    \"\"\"\n",
    "    print(f\"\\nCohort Description for MIMIC-IV and eICU Datasets\\n{'='*50}\\n\")\n",
    "    \n",
    "    # Header\n",
    "    print(f\"{'Characteristic':<20} {'MIMIC-IV':<25} {'eICU':<25}\")\n",
    "    print('-'*70)\n",
    "    \n",
    "    # Total Stays\n",
    "    print(f\"{'Total Stays':<20} {mimic_results['Total Stays']:<25} {eicu_results['Total Stays']:<25}\")\n",
    "    \n",
    "    # Race Distribution\n",
    "    print(f\"\\n{'Race Distribution':<20}\")\n",
    "    for race in mimic_results['Race Distribution'].keys():\n",
    "        mimic_data = mimic_results['Race Distribution'][race]\n",
    "        eicu_data = eicu_results['Race Distribution'][race]\n",
    "        print(f\"  {race:<18} \"\n",
    "              f\"{mimic_data['Count']} ({mimic_data['Percentage']}%)\".ljust(25) + \n",
    "              f\"{eicu_data['Count']} ({eicu_data['Percentage']}%)\")\n",
    "    \n",
    "    # Gender Distribution\n",
    "    print(f\"\\n{'Gender Distribution':<20}\")\n",
    "    for gender in mimic_results['Gender Distribution'].keys():\n",
    "        mimic_data = mimic_results['Gender Distribution'][gender]\n",
    "        eicu_data = eicu_results['Gender Distribution'][gender]\n",
    "        print(f\"  {gender:<18} \"\n",
    "              f\"{mimic_data['Count']} ({mimic_data['Percentage']}%)\".ljust(25) + \n",
    "              f\"{eicu_data['Count']} ({eicu_data['Percentage']}%)\")\n",
    "    \n",
    "    # Sepsis\n",
    "    print(f\"\\n{'Sepsis':<20} \"\n",
    "          f\"{mimic_results['Sepsis']['Count']} ({mimic_results['Sepsis']['Percentage']}%)\".ljust(25) +\n",
    "          f\"{eicu_results['Sepsis']['Count']} ({eicu_results['Sepsis']['Percentage']}%)\")\n",
    "    \n",
    "    # ARDS\n",
    "    print(f\"{'ARDS':<20} \"\n",
    "          f\"{mimic_results['ARDS']['Count']} ({mimic_results['ARDS']['Percentage']}%)\".ljust(25) +\n",
    "          f\"{eicu_results['ARDS']['Count']} ({eicu_results['ARDS']['Percentage']}%)\")\n",
    "    \n",
    "    # Age\n",
    "    print(f\"\\n{'Age (Mean ± SD)':<20} \"\n",
    "          f\"{mimic_results['Age']['Mean']} ± {mimic_results['Age']['Std']}\".ljust(25) +\n",
    "          f\"{eicu_results['Age']['Mean']} ± {eicu_results['Age']['Std']}\")\n",
    "\n",
    "# Generate descriptions\n",
    "mimic_results = cohort_description(mimic_iv_df, 'MIMIC-IV')\n",
    "eicu_results = cohort_description(eICU_df, 'eICU')\n",
    "\n",
    "# Print formatted summary\n",
    "print_cohort_summary(mimic_results, eicu_results)\n",
    "\n",
    "# Optional: Save results to a markdown file for thesis inclusion\n",
    "def save_to_markdown(mimic_results, eicu_results, filename='cohort_description.md'):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"# Cohort Description for MIMIC-IV and eICU Datasets\\n\\n\")\n",
    "        f.write(\"| Characteristic        | MIMIC-IV                     | eICU                         |\\n\")\n",
    "        f.write(\"|-----------------------|------------------------------|------------------------------|\\n\")\n",
    "        f.write(f\"| Total Stays          | {mimic_results['Total Stays']} | {eicu_results['Total Stays']} |\\n\")\n",
    "        f.write(f\"| **Race Distribution** |                              |                              |\\n\")\n",
    "        for race in mimic_results['Race Distribution'].keys():\n",
    "            mimic_data = mimic_results['Race Distribution'][race]\n",
    "            eicu_data = eicu_results['Race Distribution'][race]\n",
    "            f.write(f\"|   {race:<18} | \"\n",
    "                    f\"{mimic_data['Count']} ({mimic_data['Percentage']}%) | \"\n",
    "                    f\"{eicu_data['Count']} ({eicu_data['Percentage']}%) |\\n\")\n",
    "        f.write(f\"| **Gender Distribution** |                              |                              |\\n\")\n",
    "        for gender in mimic_results['Gender Distribution'].keys():\n",
    "            mimic_data = mimic_results['Gender Distribution'][gender]\n",
    "            eicu_data = eicu_results['Gender Distribution'][gender]\n",
    "            f.write(f\"|   {gender:<18} | \"\n",
    "                    f\"{mimic_data['Count']} ({mimic_data['Percentage']}%) | \"\n",
    "                    f\"{eicu_data['Count']} ({eicu_data['Percentage']}%) |\\n\")\n",
    "        f.write(f\"| **Sepsis**           | \"\n",
    "                f\"{mimic_results['Sepsis']['Count']} ({mimic_results['Sepsis']['Percentage']}%) | \"\n",
    "                f\"{eicu_results['Sepsis']['Count']} ({eicu_results['Sepsis']['Percentage']}%) |\\n\")\n",
    "        f.write(f\"| **ARDS**             | \"\n",
    "                f\"{mimic_results['ARDS']['Count']} ({mimic_results['ARDS']['Percentage']}%) | \"\n",
    "                f\"{eicu_results['ARDS']['Count']} ({eicu_results['ARDS']['Percentage']}%) |\\n\")\n",
    "        f.write(f\"| **Age (Mean ± SD)**  | \"\n",
    "                f\"{mimic_results['Age']['Mean']} ± {mimic_results['Age']['Std']} | \"\n",
    "                f\"{eicu_results['Age']['Mean']} ± {eicu_results['Age']['Std']} |\\n\")\n",
    "\n",
    "# Save to markdown\n",
    "save_to_markdown(mimic_results, eicu_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic_extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
